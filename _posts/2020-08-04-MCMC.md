---
layout: post
title:  "마르코프 연쇄 몬테 카를로(Markov Chain Monte Carlo)"
date: 2020-08-04
author: YoungHwan Seol
categories: Statistics
---

마르코프 체인 몬테 카를로(Markov Chain Monte Carlo), 흔히 MCMC 방법이라 알려진 이 기법은 다양한 형태의 분포로부터 parameter의 sampling을 수행할 수 있는 방법이다.

우리는 베이지안 방법론을 사용하는 과정에서 사전 분포(prior distribution)와 데이터를 바탕으로 하는 likelihood 를 곱해 사후 분포(Posterior distribution)를 결정짓는다.

$$ p(\theta\mid\mathbf{X}) \propt p(\theta)p(\mathbf{X}\mid\theta) $$

사전 분포를 선택할 때, conjugate prior를 설정하지 않는다면, 우리가 목표로하는 사후 분포는 익숙한 형태의 분포가 아닐 가능성이 아주 높다. 그래서 사후 분포에서 parameter $$\theta$$에 대한 sampling을 진행하는 것은 어려운 일이다. MCMC 방법론은 이처럼 closed form이 아닌 사후 분포에서 parameter $$\theta$$를 sampling 할 때, 유용하게 사용된다.

특히 MCMC 방법은 parameter의 차원이 높은 경우에도 수행할 수 있다는 장점을 갖고 있다. 메트로폴리스-헤스팅스(Metropolis-Hastings) 알고리즘, 깁스 샘플러(Gibbs Sampler)가 MCMC 방법론 중 하나이며 이번 포스팅에서는 MCMC 기법에 대해서 논의를 진행해보고자 한다.

#### 마르코프 체인(Markov Chain)

MCMC 기법을 이해하기 위해서는 먼저 마르코프 체인(Markov Chain)의 성질을 이해해야 한다. Markov Chain의 특징들 중에서 어떤 조건에서 Markov Chain이 특정 분포로 수렴하게 되는지를 중점적으로 살펴볼 필요가 있다.

우선 우리는 다음과 같은 확률변수의 조건부 독립성 성질을 만족함을 가정하는 것에서 Markov Chain에 대한 논의를 시작한다.

$$
p(\theta^{(t+1)}\mid\theta^{1},...,\theta^{(t)}) = p(\theta^{(t+1)}\mid\theta^{(t)})
$$

$$p(\theta^{(t+1)}\mid\theta^{(t)})$$ 란 parameter $$\theta$$가 $$\theta^{(t)}$$ 상태에서 $$\theta^{(t+1)}$$ 로 변하는 전이 확률(transition probability) $$T(\theta^{(t)},\theta^{(t+1)})$$ 이라 부르기도 한다.

그리고 모든 $$t$$ 값에 대해 transition probability가 동일한 Markov Chain을 동질적(homogeneous)인 Markov Chain이라고 말한다.

parameter $$\theta$$의 $$t+1$$ 시점의 marginalized probability $$p(\theta^{(t+1)})$$ 은 Chain 상에서 이전 $$t$$ 시점의 $$\theta$$ 의 marginalized probability에 영향을 받는다.

$$
p(\theta^{(t+1)}) = \sum_{\theta^{(t)}} p(\theta^{(t+1)}\mid\theta^{(t)})p(\theta^{(t)})
$$

만약 Chain에서 parameter $$\theta$$의 각 단계 분포가 불변한다면, 이 $$\theta$$의 분포는 Markov Chain에 대해 stationary 하다고 표현한다.

$$\theta$$의 분포 $$p(\theta)$$ 가 stationary 하기위한 충분 조건(필요 조건은 아님)은 다음과 같은 수식이 성립되는 transition probability를 활용하는 것이다. 이 수식을 detailed balanced condition 이라 부른다. 그리고 이 detailed balanced condition을 만족하는 경우 time-reversible 하다고 말한다.

$$
p(\theta^{(t+1)})p(\theta^{(t)}\mid\theta^{(t+1)}) = p(\theta^{(t)})p(\theta^{(t+1)}\mid\theta^{(t)})
$$

여기에 추가적으로 $$ t \to \infty $$인 경우, 초기 $$p(\theta^{0})$$ 을 어떻게 설정하더라도 $$p(\theta^{(t)})$$ 이 stationary한 분포로 수렴해야 한다는 조건(이를 ergodic 하다고 한다)을 만족시키면, Markcov Chain은 유일한 stationary distribution을 갖게 된다.

즉, detailed balanced condition을 만족한다면 우리는 parameter $$\theta$$에 대한 stationary distribution이 존재한다는 것을 알 수 있고 ergodic성까지 만족한다면, 우리는 유일한 stationary distribution이 존재한다고 말할 수 있다.

#### Markov Chain vs MCMC





####참조 문헌
1. [PRML](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf) <br>
