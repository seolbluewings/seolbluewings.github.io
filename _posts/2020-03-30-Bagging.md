---
layout: post
title:  "Bagging and Random Forest"
date: 2020-03-30
author: seolbluewings
categories: Ensemble
---

앙상블(Ensemble) 기법은 다수의 기초 학습기를 생성하고 이를 결합하여 학습을 시도하는 것을 의미한다. 앙상블이란 단어를 '여러가지 알고리즘을 모아 성능을 향상시키는 것'이라 이해할 수 있다. 앙상블 기법을 통해서 우리는 보통 더 안정적이고(More Stability) 더 예측력이 높은(Better Accuracy) 모델을 생성해낼 수 있다.

#### 앙상블 개요

![BA](https://github.com/seolbluewings/seolbluewings.github.io/blob/master/assets/Ensemble.png?raw=true){:width="70%" height="70%"}{: .center}

그림처럼 앙상블은 base learner를 생성하고 이를 결합하여 더 예측력이 높은 모델을 만들어낸다. 만약 앙상블 모델 생성 과정에서 모두 동일한 base learner를 생성한다면, 이를 동질적(homogenous)인 앙상블이라 부른다. 의사결정나무들을 모아서 랜덤 포레스트 모델을 만드는 것이 바로 동질적 앙상블인 것이다. 같은 것끼리 모으는 앙상블이 있다면 다른 것끼리 모으는 앙상블도 존재할 것이다. 이를 이질적(heterogenous) 앙상블이라 하며 스태킹(Stacking)이 이 이질적 앙상블의 한 종류라고 할 수 있다. 어쨌든 앙상블 모델은 다수의 base learner를 결합하여 단일 학습기보다 더 좋은 성능을 얻어낸다.

#### 부트스트랩(Bootstrap)

부트스트랩은 학습데이터에서 임의의 복원 추출을 진행하는 것이다. 데이터가 N개 존재한다면, 복원 추출을 통해 N개의 데이터를 가진 집합을 만들어낸다. 복원추출이기 때문에 선택되지 못하는 데이터가 발생할 것이다. 그런 데이터들은 각 부트스트랩 샘플의 OOB(Out of Bag)라고 불린다. OOB는 Validation Set과 같이 성능을 측정하기 위한 용도로 활용될 수 있다.

N개의 전체 데이터에서 N번 데이터를 복원 추출하면, 각 데이터가 나타날 확률은 0.632이며 이에 대한 수학적인 계산은 다음과 같다.

$$
\begin{align}
\text{Pr}(\text{Observation} i \in \text{Bootstrap Sample}) &= 1-\prod_{i=1}^{N}\left(1-\frac{1}{N}\right) \\ \nonumber
&= 1-\left(1-\frac{1}{N}  \right)^{N} \\ \nonumber
&\simeq 1-e^{-1} =0.632 \nonumber
\end{align}
$$

#### 배깅(Bagging)

배깅(Bagging)은 부트스트랩(Bootstrap)하고 합친다(Aggregating)을 합친 말이라고 할 수 있다. 배깅의 과정은 다음의 그림과 같다.

![BA](https://github.com/seolbluewings/seolbluewings.github.io/blob/master/assets/Bagging.PNG?raw=true){:width="70%" height="70%"}{: .center}

부트스트랩을 통해 생긴 개별적인 데이터셋에 개별적인 모델을 생성하게 되고 따라서 각 모델이 만들어지는 과정은 다른 모델이 만들어지는 과정에 영향을 주지 않는다. 따라서 배깅은 Parallel Ensemble이라 불리기도 한다.

이 글의 초반부에 여러 알고리즘을 모아 성능을 향상시키는 것이 앙상블 방법이라고 언급하였다. 배깅은 여러가지 모델을 만드는 것이기 때문에 배깅을 통해 우리는 더 안정적이고 예측력 높은 모델을 만들 수 있어야할 것이다. 왜 배깅이 개별 의사결정나무보다 더 좋은가? 왜 배깅이 통하는가?

기초통계 시간에 배웠던 사례를 하나 떠올려보자. 각각의 분산이 $$\sigma^{2}$$인 n개의 독립변수 $$Z_{1},Z_{2},...Z_{n}$$이 있을 때, $$\text{Var}(\bar{Z}) = \frac{\sigma^{2}}{n}$$ 이라는 것을 떠올려 보자.

따라서 우리는 관측값들의 평균을 구해 분산을 감소시키는 것을 확인할 수 있다. 배깅도 똑같은 절차를 밟는 것이라 할 수 있다. 통계적 학습 방법론의 분산을 감소시키는 것은 결국 1. 모집단에서 많은 트레이닝셋을 만들어내고 2. 각 트레이닝셋을 통해 분리된 예측 모델을 만들어내 3. 모든 예측의 평균을 내는 것이다. 의사결정나무는 1,0으로 결국 값을 나타내줄 것이기 때문에 이를 투표한다고 표현하기도 한다.

배깅이 통하는 이유를 조금 더 수학적으로 표현하자면 다음과 같을 것이다. 여기서 B는 B개의 부트스트랩 트레이닝 데이터셋을 의미하는 것이다. b번째 부트스트랩 트레이닝셋에서 만든 모델을 $$\hat{f}^{*b}(x)$$ 라고 표현하자. 그렇다면 배깅은 다음과 같이 표현할 수 있다.

$$ \hat{f}_{\text{bag}}(x) = \frac{1}{B}\sum_{b=1}^{B} \hat{f}^{*b}(x)$$

그러나 배깅에도 여전히 한계는 존재한다. 배깅의 과정에서 만들어진 의사결정나무는 분기 기준이 비슷할 것이기 때문에 결국 서로 비슷한 모델일 것이다. 따라서 생성된 모델들 간의 Correlation 값이 높을 것이고 이로 인하여 배깅은 의도만큼 분산을 줄이지 못할 수 있다.

분산이 $$\sigma^{2}$$인 B개의 i.i.d(identically, independently distributed) 확률변수의 평균값의 분산은 $$\frac{\sigma^{2}}{B}$$이다. 그러나 i,d(identically distributed, not independent) 조건에서는 correlation 값이 $$\rho$$일 때, 확률변수 평균값의 분산은 $$ \rho\sigma^{2}+\frac{1-\rho}{B}\sigma^{2} $$ 이다. B의 개수를 높이면 두번째 항의 값이 작아지겠지만, 배깅하는 의사결정나무 모델들간의 Correlation이 양수라면, 평균내는 효과가 감소된다.

Bias-Variance Trade Off 관점에서 이를 살펴보면, Bagging은 분산을 줄이는 것에 초점을 둔 방법이라 할 수 있다. 따라서 Bagging은 Pruning과정을 수행하지 않은 의사결정나무, Neural Network처럼 데이터 변화에 민감한 base learner를 가질 때 좋은 성능을 보인다.

#### 랜덤 포레스트(Random Forest)

따라서 랜덤 포레스트의 기반이 되는 아이디어는 생성되는 나무들 사이의 correlation을 줄임으로써 Bagging의 분산 감소의 정도를 향상시키는 것이다. 이러한 목표는 의사결정나무를 성장시킬 때, 변수를 랜덤하게 선택함으로써 달성할 수 있다. 그래서 랜덤 포레스트라고 불리는 것이며 이 과정으로 인해 기존의 Bagging과의 차이가 발생한다. 랜덤 포레스트는 대표적인 앙상블 기법으로 Bagging을 살짝 변경했음에도 성능이 크게 향상된다는 특징이 있다.

의사결정나무는 특정 노드에서 분기할 때, 입력 데이터의 차원(d차원이라 하자) 중 해당 분기에서 최적의 변수 1개를 선택한다. 즉, 분기 과정에서 속성(feature)를 모두 고려해서 분기에 활용할 속성을 결정한다. 반면에 랜덤 포레스트는 d차원 중, 랜덤하게 k차원의 속성을 선택한다. $$(k \leq d)$$ 그리고 이 k개의 속성 중 최적의 속성을 구해 분기를 진행한다. 즉 활용하는 변수에 대한 Sampling을 진행하는 것이다. 일반적으로 최적의 k값은 $$k=\log_{2}{d}$$ 로 알려져있다.

![BA](https://github.com/seolbluewings/seolbluewings.github.io/blob/master/assets/RF.PNG?raw=true){:width="70%" height="70%"}{: .center}

Bagging은 base learner의 다양성을 Bootstrap이라는 샘플링 기법으로 증가시켰는데 랜덤 포레스트는 Bootstrap뿐만 아니라 속성(feature)을 랜덤으로 선택하는 과정까지 추가되어 성능을 더욱 향상시켰다. 이는 앙상블 모델의 일반화 성능이 개별 base learner의 차이를 증가시킴으로써 향상시킬 수 있음을 의미하는 바이기도 하다.


#### 참고문헌

1. [ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)
2. [PRML](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)
2. [단단한 머신러닝](http://www.yes24.com/Product/Goods/88440860)










