---
layout: post
title:  "TF-IDF"
date: 2021-03-10
author: seolbluewings
categories: Statistics
---

TF-IDF 개념은 여러 문서가 존재하는 상황에서 특정 단어가 특정 문서 내에서 얼만큼의 중요도를 갖는지 보여주는 통계적인 수치로 텍스트 마이닝 분석에서 가중치로 빈번하게 활용되는 값이다.

TF-IDF는 문서 내에서 단어의 활용 횟수만을 중요시하는 Bag of Words 가정에서 출발한다. Bag of Words는 말하고자 하는 주제가 단어의 사용 빈도에 의해 결정된다고 바라보는 것에서 시작하여 단어의 등장 횟수만 중요할 뿐 단어의 등장 순서는 중요하지 않다고 본다. 이러한 Bag of Words 가정에서 가장 빈번하게 사용되는 통계량이 바로 TF-IDF 이다.

#### TF-IDF 정의

총 $$D$$개의 문서가 존재한다고 가정 하자. $$D = \{d_{1},...,d_{D}\}$$. D개의 문서에는 총 M개의 단어가 존재한다고 하자. $$W = \{w_{1},...w_{M}\}$$

- TF(Term Frequency) : 특정 문서에서 특정 단어의 등장 횟수

TF는 특정 문서 $$d_{i}$$에서 단어 $$w_{j}$$의 등장 횟수를 의미한다. 단어 $$w_{j}$$가 문서 $$d_{i}$$에서 3번 등장했다면, TF($$d_{i},w_{j}$$) = 3 으로 표현이 가능하다. 앞선 포스팅들 중에서 '분포' 란 단어의 TF를 계산해본다면, TF(GMM, 분포) = 23, TF(PCA, 분포) = 1 이다. TF통계량은 단어 사용빈도가 문서의 주제와의 양의 상관관계가 있을 것이라는 가정에 기반하는 값이다.

- DF(Document Frequency) : 특정 단어가 등장한 문서의 수

DF는 특정 단어 $$w_{j}$$가 등장한 문서의 수를 의미한다. 단어 $$w_{j}$$가 전체 D개의 문서 중에서 $$d_{1},d_{5},d_{9}$$에서만 등장했다면, DF($$w_{j}$$) = 3 이다. DF는 각 문서 내에서 해당 단어가 몇번 등장했는지에 대해서는 신경쓰지 않는 값이며 DF 값이 클수록 많은 문서에서 활용되는 범용적인 단어라고 간주할 수 있다.

- IDF(Inverse Document Frequency)

전체 문서의 수를 특정 단어의 DF 값으로 나눈 후 로그함수를 취한 값이다. 수식으로 표현하면 다음과 같은 형태를 지닌다.

$$ IDF(w_{j}) = \log{\left(\frac{D}{1+DF(w_{j})}\right)} $$

IDF의 수식 형태를 통해서 우리는 IDF의 2가지 특징을 유추해볼 수 있다.

1. IDF값의 형태를 고려하면 DF(w)값이 큰 단어는 IDF값이 작게 나온다. 즉, 모든 문서에서 등장할 법한 단어는 문서를 구별해내거나 문서의 주제를 파악하는데 중요도가 떨어진다고 볼 수 있다.

2. 반면에 DF(w)값이 작은 단어는 IDF값이 크다. 이는 극히 적은 문서에서 발견되는 단어는 문서를 구별해내거나 문서의 주제를 파악하는데 중요도가 크다고 볼 수 있다.

단어 w의 TF-IDF값은 TF통계량과 IDF통계량의 곱셈을 통해 구한다. 만약 단어 w의 문서 d에 대한 주제 예측력이 높다면, TF-IDF값이 클 것이다. 해당 문서에서 많이 언급되었을 것이며 동시에 다른 문서에서는 적게 언급되었을 단어이기 때문이다. 반대로 단어 w의 문서 d에 대한 주제 예측력이 낮다면, TF-IDF값은 낮을 것이다.


#### 참조 문헌
1. [위키백과 TF-IDF](https://ko.wikipedia.org/wiki/Tf-idf) <br>
2. [한국어 임베딩](https://ratsgo.github.io/natural%20language%20processing/2019/09/12/embedding/)
