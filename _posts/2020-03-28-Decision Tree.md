---
layout: post
title:  "의사결정나무(Decision Tree)"
date: 2020-03-28
author: YoungHwan Seol
categories: MachineLearning.
---

의사결정나무는 스무고개 놀이와 비슷한 알고리즘이라 할 수 있다. 내가 생각한 인물을 맞춰내는 아키네이터 게임과 유사한 방식으로 알고리즘이 작동한다. 아래 그림은 유명한 타이타닉 데이터의 Y값인 생존여부를 맞추는 과정이며, 의사결정나무는 위와 같이 Y/N 형식의 대답이 나올 수 밖에 없는 알고리즘을 학습을 진행하게 된다. 그 결과 우리는 개인이 타이타닉호에서 생존했는지 사망했는지를 결정지을 수 있게 된다.

![DT](https://github.com/seolbluewings/seolbluewings.github.io/blob/master/assets/DT1.PNG?raw=true)

따라서 의사결정나무를 학습한다는 것은 정답에 가장 빨리 도달하는 Y/N질문을 학습하는 것이라 말할 수 있을 것이며, 궁극적으로 우리는 데이터를 가장 잘 분류하는 의사결정나무 모형을 만들고자 한다.

타깃변수(Y)의 형태에 따라 의사결정나무는 2가지 종류로 나뉜다. 위처럼 Y가 범주형일 때, 의사결정나무는 분류를 위한 Classification Tree로 불린다. 그러나 Y가 연속형일 때, 의사결정나무는 Regression Tree로 불린다. 그런데 보통 의사결정나무는 Y가 범주형인 상황에서 자주 사용되므로 Classification Tree의 경우에 포커스를 맞추고자 한다. 

#### 용어 정의

의사결정나무를 이해하기 위해 의사결정나무에서 빈번히 사용되는 용어들에 대해 먼저 정리하도록 하자. 의사결정나무는 아래 그림과 같은 큰 틀을 가지고 있다.

![DT](https://github.com/seolbluewings/seolbluewings.github.io/blob/master/assets/DT2.PNG?raw=true)

각각의 질문은 노드(node)라고 불린다. 그 중에서도 첫번째 노드는 뿌리 노드(Root Node)라고 불린다. 데이터를 분류하는 과정에서 가장 먼저 사용되는 질문인 것으로 가장 효율적인 Y/N 질문이 여기 배치될 것이다. 그 다음 나무의 가지가 쳐지는 과정을 분기(Splitting)이라 한다. 분기를 통해 생성된 하위 노드를 자식 노드(Child Node)라고 부르며, 분기가 이루어진 상위 노드를 부모 노드(Parent Node)라 한다.

분기라는 것은 즉, 노드 1개를 2개 혹은 그 이상의 서브 노드(Sub Node)로 나누는 과정이다. (이후의 과정에서는 분기할 때는 2개의 서브 노드로 나뉘는 것만 생각하자) 따라서 분기를 진행하면 각 노드에 속한 데이터의 수는 줄어들 것이다.

분기를 여러번 거치면, 최종 단계의 노드가 발생하게 된다. 이 노드를 Leaf Node나 Terminal Node라고 부른다. Terminal Node의 모든 데이터를 합치면 그 갯수는 Root Node에 있는 데이터의 갯수와 동일할 것이다. 만약 Terminal Node가 단 1개의 타깃변수(Y)로만 존재한다면, 이를 Pure Node라고 부른다.

자 이제 본격적으로 의사결정나무를 만드는 과정을 살펴보도록 하자. 의사결정나무는 데이터를 분류하는 과정이기 때문에 어떤 기준을 세워야 데이터가 잘 분리되는지 고민해야 한다.

이는 타깃 변수(Y)의 분류를 위해 어떤 X변수(Attribute)를 선택해야 하는가? 어떤 X변수가 데이터에 대한 확실한 정보를 제공하고 있는가? 라는 질문으로 환원될 수 있을 것이다. 앞서 확인했던 타이타닉호 예시를 생각해보자. 배가 침몰하는 과정에서 아이와 여성을 먼저 구출했을 것이므로 희생자의 다수는 남성이다. 따라서 개인의 생존/사망 여부를 분류하는 과정의 첫번째 질문은 '이 사람의 성별이 남성인가?' 이다. 이처럼 의사결정나무는 각 단계에서 데이터를 가장 잘 분리해낼 수 있는 기준을 찾아 그에 대한 질문을 던진다.

#### CART Algorithm

Y가 범주형 변수(0,1)일 때, 활용할 수 있는 대표적인 분기 기준은 지니 계수(Gini Index)이다. 지니 계수를 이용하는 알고리즘은 CART 알고리즘이다. CART 알고리즘은 1번의 분기에 1개의 X변수만을 사용하며 해당 분기에서는 데이터를 2개의 Sub Node로 분리한다.

만약 분기에 사용하는 X변수가 숫자형(Numerical)일 때, 특정값보다 큰지(또는 작은지) 여부를 따지게 된다. 앞선 그림에서 나이가 9.5세보다 많은가 여부를 따지는 것과 같은 케이스를 생각하면 된다. 만약 명목형(Nominal) 변수일 때는 특정 집합 안에 속하는가 여부를 따지게 된다. 마찬가지로 앞선 그림을 통해 예시를 들자면, 남성인지 아닌지를 따지는 것과 같은 케이스를 생각하면 된다.

CART Algorithm은 노드를 분기할 때, 불순도(impurity)를 고려한 Greedy Search를 진행한다. 분기 이전 부모 노드(Parent Node)의 불순도를 계산하고 분기 후 자식 노드(Child Node)의 불순도를 계산하여 불순도가 낮아지는 분기, 또 여러가지 X변수들 중에서도 불순도 개선이 가장 뛰어난 X를 선택하여 분기를 진행한다.

Greedy Search라는 것은 시행가능한 모든 경우의 수를 따져본다는 것을 의미한다. 만약 분기 기준이 되는 X변수가 연속형 변수라면, 우선 연속형 변수의 유일한(unique) 관찰값을 먼저 구한다. 만약 유일한 관찰값이 M개라면, 이 유일한 값들을 순서대로 정렬한 이후, M-1번의 Greedy Search를 진행한다. 자세한 방법은 아래서 보여줄 것이다.

만약 분기 기준이 되는 X변수가 범주형 변수라면, 몇개의 범주로 구성되는지를 따져본다. Q개의 범주로 구성된다면 $$ 2^{(Q-1)}-1$$ 가지 경우의 수가 존재하게 된다. Greedy Search에서 시행하는 횟수는 이와 같고 이렇게 여러가지 시행을 모두 진행한 이후, 불순도 개선이 가장 뛰어난 것을 분기 기준으로 선택하게 된다.

우선 불순도(Impurity)를 어떻게 따져볼 수 있는가를 생각해보아야 한다. 앞서 언급한 지니 계수(Gini Index)를 불순도 측정에 사용한다. 지니 계수의 식은 다음과 같으며 값이 가장 작은 경우를 선택한다.

$$
\text{Gini Index} = \sum_{i=1}^{m}p_{i}(1-p_{i}) = 1-\sum_{i=1}^{m}p_{i}^{2}
$$

지니 계수를 계산하는 예시를 살펴보도록 하자. 다음과 같이 총 8명이 존재하며 이들이 사기행위를 벌이는지 여부를 알아보고자 한다. 
















##### 이 글은 다음의 [교재](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=128569893)를 참고하였음을 밝힙니다. 










