---
layout: post
title:  "군집 분석(Cluster Analysis)"
date: 2020-06-12
author: YoungHwan Seol
categories: Statistics
---

군집 분석(Cluster Analysis)은 대표적인 비지도 학습법으로 관측값 $$\mathbf{X} = \{x_{1},x_{2},...,x_{N}\} $$ 을 적절한 기준에 따라 관측값을 군집이라 불리는 여러개의 부분집합으로 할당하는 방법이다. 즉 데이터의 Segmentation 과정인 것이다.

군집 분석의 목적은 각 군집 내의 개체들을 다른 군집에 속하는 개체들보다 서로 더 유사하도록 여러 군집으로 나눈 후, 각 군집별 특성을 파악함으로써 전체 데이터에 대한 이해를 시도하는 방식이다. 군집 분석에 활용되는 데이터는 타깃 변수($$\mathbf{y}$$) 없이 모든 변수가 독립 변수로만 이루어져있다는 특징을 갖는다.

이번 포스팅에서는 대표적인 군집 분석 방식인 K-평균 군집화(K-means Clustering) 알고리즘과 DBSCAN 알고리즘을 알아보고자 한다. 두개의 알고리즘은 각각 중심 기반(center-based) 군집화, 밀도 기반(density-based) 군집화라는 차이를 갖는다.

중심 기반 군집화는 동일한 클래스에 속하는 데이터는 어떤 중심점을 기준으로 분포할 것이라는 가정에 기반하는 방식이다. 군집의 중심을 기준으로 가까운 데이터를 1개의 집단으로 묶는 것으로 원 형태의 집단 모양이 형성된다.

밀도 기반 군집화는 동일한 클래스에 속하는 데이터는 서로 비슷한 분포를 가질 것이라는 가정에 기반한다. 이 방식은 데이터가 불특정 분포를 따르는 경우 활용하는 것이 적절하다.

#### K-평균 군집화

K-평균 군집화(이하 K-means Clustering) 알고리즘은 가장 기본적이면서 동시에 가장 많이 활용되는 알고리즘이다. 이 알고리즘은 분석 이전에 분석자가 K값을 설정해야 한다는 특징을 갖는다. 아무튼 K값이 주어졌다고 가정하고 논의를 시작하자.

한 집단에 속한 데이터들 간의 거리가 서로 다른 집단에 속한 데이터들 간의 거리보다 더 가까울 수 있도록 집단을 나누는 것이 상식적이다. 각 집단의 중심점을 $$\mu_{K} = \{\mu_{1},...,\mu_{k}\}$$ 을 도입하면, 우리는 각각의 데이터 포인트로부터 가장 가까운 $$\mu_{k}$$ 를 선택하여 각각의 데이터를 해당 집단에 할당해야 한다.

각각의 데이터 포인트를 군집에 할당시키는 과정은 다음과 같이 표현될 수 있다. 이 과정에서 우리는 이진 변수 $$r_{nk} \in \{0,1\}$$ 를 도입한다. 여기서 $$k = 1,2,...,K $$이며 이 변수는 변수 $$\mathbf{X}=\{x_{1},....x_{N}\}$$ 중 $$x_{n}$$ 이 K개의 군집 중에서 어느 곳에 속하는지를 나타내는 값이다. 만약 k번째 집단에 속하게 된다면 $$r_{nk} = 1$$ 이고 $$j \neq k$$인 나머지에 대해서는 $$r_{nj} = 0 $$ 이다. 이 이진변수를 도입하면 각각의 데이터 포인트의 최소 거리를 갖게 만드는 집단을 찾는 과정은 다음과 같은 수식으로 표현할 수 있다. 여기서 $$\mu_{k}$$ 는 k번째 군집의 중심점을 의미한다.

$$ J = \sum_{n=1}^{N}\sum_{k=1}^{K} r_{nk}\mid\mid x_{n}-\mu_{k} \mid\mid^{2}$$

이를 뒤틀림 척도(distortion measure)라고 표현하기도 한다. 우리의 목표는 함수 $$J$$ 를 최소화하는 $$r_{nk}$$ 값과 $$\mu_{k}$$ 값을 발견해내는 것이다.

$$ \text{argmin}_{r,\mu} \sum_{n=1}^{N}\sum_{k=1}^{K} r_{nk}\mid\mid x_{n}-\mu_{k} \mid\mid^{2}$$

이는 $$r_{nk}$$에 대한 최적화와 $$\mu_{k}$$ 에 대한 최적화 두가지 과정을 반복함으로써 성취해낼 수 있다. 일종의 EM 알고리즘과 유사한 과정을 거치는 것이다.

1. 가장 먼저 $$\mu_{k}$$ 에 대한 초기값을 설정해야 한다. 
2. $$\mu_{k}$$ 값을 고정한 상태로 J를 최소화시키는 $$r_{nk}$$ 값을 찾는다.
3. $$ r_{nk} $$ 값을 고정한 채로 J를 최소화하는 $$\mu_{k}$$를 찾는다.
4. 값이 수렴할 때까지 (혹은 지정한 반복 횟수까지) 2,3단계 과정을 반복한다.

$$r_{nk}$$는 다음과 같이 구할 수 있다. 함수 $$J$$ 는 $$r_{nk}$$의 선형 함수이며 서로 다른 $$n$$에 해당하는 항은 각각에 대하여 독립적이다. 그래서 각각의 $$n$$에 대하여 개별적인 최적화를 시행할 수 있다. 그래서 각 $$n$$에 대하여 $$ \mid\mid x_{n}-\mu_{k}\mid\mid^{2}$$ 를 최소화시키는 $$k$$ 값에 대하여 $$r_{nk} = 1$$ 로 결정지으면 된다. 말로 길게 표현한걸 수식으로 간단히 줄이면 다음과 같다.

$$
r_{nk} =
\begin{cases}
1 \quad \text{if} \quad k= \text{argmin}_{j} \mid\mid x_{n}-\mu_{j}\mid\mid^{2} \\
0 \quad \text{else}
\end{cases}
$$

$$r_{nk}$$ 값을 고정한 상태로 $$\mu_{k}$$값을 찾는 과정은 다음과 같다. 함수 J는 $$\mu_{k}$$에 대하여 제곱 형태를 갖는다. 제곱 형태일 때 함수의 최소값을 갖는 경우는 $$\mu_{k}$$ 에 대한 미분값을 0으로 하는 지점에서 발견할 수 있다.

$$ 2\sum_{n=1}^{N}r_{nk}(x_{n}-\mu_{k}) = 0 $$
$$ \mu_{k} &= \frac{\sum_{n}r_{nk}x_{n}}{\sum_{n}r_{nk}} $$

두번째 수식의 분모는 군집 k에 할당된 데이터 포인트의 개수를 의미하게 되며, 따라서 $$\mu_{k}$$ 는 군집 k에 할당된 데이터 포인트의 평균이라 해석할 수 있다. 그래서 이 알고리즘을 K-평균 알고리즘이라 부르는 것이다. 이러한 2가지 최적화 과정을 반복해서 진행하여 각 군집에 할당되는 데이터 포인트에 변화가 없을 때 알고리즘이 작동이 종료된다.

